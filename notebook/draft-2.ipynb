{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "63bb3135-5926-454e-ac97-a872bf12b9ab",
   "metadata": {},
   "source": [
    "# Dependencies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad1ec842-ebc1-4cac-8aba-69cd91ceb864",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e99d622e-2658-4d39-a545-ff1707e3afec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text Extraction\n",
    "from pdfminer.high_level import extract_text\n",
    "\n",
    "# Preprocessing\n",
    "import re\n",
    "import nltk\n",
    "import spacy\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "\n",
    "# Embedding Generation\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# Semantic Chunking\n",
    "from sklearn.cluster import KMeans\n",
    "from kneed import KneeLocator\n",
    "import numpy as np\n",
    "\n",
    "# LLM for summarization\n",
    "import os\n",
    "from getpass import getpass\n",
    "from openai import OpenAI\n",
    "\n",
    "# Warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afca3573-e78e-4f93-9b0f-5016291a0950",
   "metadata": {},
   "source": [
    "## Module Downloads"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5861107-d112-4f1b-8312-628dd4d0f3d2",
   "metadata": {},
   "source": [
    "### Preprocessing Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7a822b5f-e0b5-4b44-bcad-6c842786da28",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Akash\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Akash\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Akash\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# !python -m spacy download en_core_web_sm\n",
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "691f6a59-47ad-4824-b746-1a68561efcc5",
   "metadata": {},
   "source": [
    "### Tokenization Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a122712d-ad31-4881-ab5c-c1c677226eee",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SentenceTransformer('bert-base-nli-mean-tokens')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e284696a-7413-45b1-b8ae-d1022f4a3a6d",
   "metadata": {},
   "source": [
    "## LLM API Key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0082f217-6238-4f6d-aa0a-3bbc45afc0eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter OpenAI API Key: ········\n"
     ]
    }
   ],
   "source": [
    "OPENAI_API_KEY = getpass('Enter OpenAI API Key:')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f795a026-09a8-4792-9cc4-910f18ebd2c3",
   "metadata": {},
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7c90f56-4509-4ea1-b7c4-c59fc7e8f251",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "241e7cbe-aa54-4650-bd7e-4745a41e3a0e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Data Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3e4041d2-ed15-4adc-9981-9ed0dfbb344b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _extract_text_from_pdf(filepath):\n",
    "    text = extract_text(filepath)\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04d0fb17-bc67-41ce-8716-aac1d00d1b2c",
   "metadata": {},
   "source": [
    "### Data Prepration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f66f3bda-7d90-4dac-b874-b54ed7d6645c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _preprocess_text(text):\n",
    "    text = re.sub(r'[^\\x00-\\x7F]+', '', text)\n",
    "    doc = nlp(text)\n",
    "    \n",
    "    processed_tokens = []\n",
    "    for token in doc:\n",
    "        if token.ent_type_ in ('PERSON', 'ORG', 'GPE', 'LOC'):\n",
    "            processed_tokens.append(token.text)\n",
    "        else:\n",
    "            processed_tokens.append(token.text.lower())\n",
    "\n",
    "    text = ' '.join(processed_tokens)\n",
    "    words = word_tokenize(text)\n",
    "\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    words = [word for word in words if word not in stop_words]\n",
    "\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    words = [lemmatizer.lemmatize(word) for word in words]\n",
    "    preprocessed_text = ' '.join(words)\n",
    "    \n",
    "    return preprocessed_text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "802595ff-8b0a-4388-8619-1a27d9cd3907",
   "metadata": {},
   "source": [
    "### Semantic Chunking Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "15c0183c-7d48-47db-9381-591a8010a10a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _embedding_generation(preprocessed_text):\n",
    "    sentences = sent_tokenize(preprocessed_text)\n",
    "    sentence_embeddings = model.encode(sentences)\n",
    "    \n",
    "    return sentence_embeddings, sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4811df70-ce1d-4beb-a51d-bfef8487a466",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _find_optimal_clusters(sentence_embeddings, max_clusters=10):\n",
    "    wcss = []\n",
    "    for i in range(1, max_clusters + 1):\n",
    "        kmeans = KMeans(n_clusters=i, n_init='auto', random_state=42)\n",
    "        kmeans.fit(sentence_embeddings)\n",
    "        wcss.append(kmeans.inertia_)\n",
    "    \n",
    "    kneedle = KneeLocator(range(1, max_clusters + 1), wcss, curve=\"convex\", direction=\"decreasing\")\n",
    "    optimal_clusters = kneedle.elbow\n",
    "\n",
    "    return optimal_clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f838298b-eb21-4134-986c-6abaf8c19706",
   "metadata": {},
   "source": [
    "### Semantic Chunking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "120723e7-3fdc-43b3-b6ac-aba8ab7a4ab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _semantic_chunking(preprocessed_text, max_clusters=10):\n",
    "    sentence_embeddings, sentences = _embedding_generation(preprocessed_text)\n",
    "    \n",
    "    optimal_clusters = _find_optimal_clusters(sentence_embeddings, max_clusters)\n",
    "    \n",
    "    kmeans = KMeans(n_clusters=optimal_clusters, n_init='auto', random_state=42)\n",
    "    kmeans.fit(sentence_embeddings)\n",
    "\n",
    "    clusters = {}\n",
    "    for idx, label in enumerate(kmeans.labels_):\n",
    "        if label not in clusters:\n",
    "            clusters[label] = []\n",
    "        clusters[label].append(sentences[idx])\n",
    "\n",
    "    return clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f3c2052-8afc-4b6f-83d8-80750055211e",
   "metadata": {},
   "source": [
    "### Abstractive Summarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1d25fd33-afc2-460f-97e8-c0b1a1b1d7bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _abstractive_summary(clusters):\n",
    "    client = OpenAI(api_key=OPENAI_API_KEY)\n",
    "    summary = []\n",
    "    for cluster in clusters.values():\n",
    "        \n",
    "        cluster_text = ' '.join(cluster)\n",
    "        chunk_summary = client.chat.completions.create(\n",
    "            messages=[\n",
    "                {\n",
    "                    'role': 'user',\n",
    "                    'content': f\"Provide a well detailed technical summary of the following text:\\n{cluster_text}\"\n",
    "                }\n",
    "            ],\n",
    "            model='gpt-3.5-turbo'\n",
    "        )\n",
    "        summary.append(chunk_summary.choices[0].message.content.strip())\n",
    "\n",
    "    summary_text = ' '.join(summary)\n",
    "    final_summarization = client.chat.completions.create(\n",
    "        messages=[\n",
    "            {\n",
    "                'role': 'user',\n",
    "                'content': f\"Improve the semantic format:\\n{summary_text}\"\n",
    "            }\n",
    "        ],\n",
    "        model='gpt-3.5-turbo'\n",
    "    )\n",
    "        \n",
    "    return final_summarization.choices[0].message.content.strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e279259-796d-43bf-8a73-1e4d8ea63484",
   "metadata": {},
   "source": [
    "## Executable Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cf93b333-05bf-4c54-8162-28e095013b0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_pdf(filepath, n_clusters=5):\n",
    "    text = _extract_text_from_pdf(filepath)\n",
    "    preprocessed_text = _preprocess_text(text)\n",
    "    semantically_chunked_text = _semantic_chunking(preprocessed_text, n_clusters)\n",
    "    summary = _abstractive_summary(semantically_chunked_text)\n",
    "\n",
    "    return summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c686950-765f-4650-90d4-fccd8dc378a8",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e9dcdb59-39a0-44fc-9ec9-0f303ed27fd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = 'PDFs/1.pdf'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b76e3f22-f331-4c5d-98c4-78fd4f58bfe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = summarize_pdf(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "59ef3c32-ff66-4814-98e1-c399a02b1c12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The text explores the security of machine learning (ML) models in adversarial environments, highlighting their susceptibility to manipulation by skilled adversaries. While ML has demonstrated exceptional performance in applications like autopilot, facial recognition, and spam detection under benign conditions, the manipulation of data in adversarial settings can produce adversarial examples that compromise model performance.\n",
      "\n",
      "Researchers in academic and industrial settings have extensively studied the security of ML algorithms in adversarial scenarios, analyzing security models, adversarial attack methods, and defense strategies. The text also provides insights into future research directions for developing secure ML models.\n",
      "\n",
      "Advancements in deep learning have raised concerns about the vulnerability of ML models to attacks during training and testing. Various defense strategies have been proposed, including adversarial training, data compression, and defensive distillation. Techniques to safeguard data privacy, such as differential privacy and homomorphic encryption, have also been explored.\n",
      "\n",
      "The text stresses the importance of securing ML models in adversarial environments and underscores the need for robust defense strategies. Acknowledgments for research support and disclosure of authors' conflicts of interest are included, along with references to relevant works in the field.\n",
      "\n",
      "Additionally, the text delves into the deployment and security of ML models in parallel distributed computing environments, discussing potential attack surfaces, challenges in interpretability and robustness in deep neural networks, and defense strategies utilizing generative adversarial networks and feature squeezing methods. The authors introduce DeepCloak as a method for defending against adversarial attacks, exploring techniques like foveation-based methods and feature squeezing to enhance model security.\n",
      "\n",
      "By referencing various studies and authors, the text underscores the significance of data security and model interpretability in ML and distributed computing. Evaluation methods and considerations for deploying secure ML models in real-world applications are also discussed, providing a comprehensive overview of challenges and strategies for securing ML models in parallel distributed computing environments.\n"
     ]
    }
   ],
   "source": [
    "print(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef0eabeb-7068-4a04-9617-56a1898934db",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
